{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWJEEn5Y1Vma"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/neo4j-field/call-transcripts-automation/blob/main/students/2_PostIngestionProcessing.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU7TtmuElP9I"
      },
      "source": [
        "# Post Ingestion Processing Overview\n",
        "\n",
        "This is a [Python](https://www.python.org/) project for constructing a business-process aware knowledge graph for customer service automation and acceleration.\n",
        "\n",
        "This notebook takes the ingested transcripts and further enchances the data retrieved by ChatBot for greater clarity and accuracy.\n",
        "\n",
        "Firstly, we ask the LLM to extract elements that represent the process executed during the call (Actions, Observations, States, Resolutions, etc) and store these entities into the Knowledge Graph, including transitions between actions during calls.\n",
        "\n",
        "Then we configure the agent to execute GDS algorithms and write the results back to the graph. This process encompasses the following tasks:\n",
        "\n",
        "- Create a GDS session\n",
        "- Create a GDS projection\n",
        "- Execute Centrality Algorithm (pageRank)\n",
        "- Execute Community Detection (WCC)\n",
        "- Store the Communities in Neo4j\n",
        "- Close the GDS session\n",
        "\n",
        "We then have the agent take relationships between the observations and \"lift up\" to the process element.\n",
        "\n",
        "Lastly, we infer names for Processes by consulting with an LLM to group Processes and Actions by community id."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugn9JlZDZzFi"
      },
      "source": [
        "**Update Student's environment code (received via email)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LC0GwwNNZtSZ"
      },
      "outputs": [],
      "source": [
        "# The student's environment file (aura.env) will be downloaded into the notebook's\n",
        "# files after executing the 'Setup' section.\n",
        "STUDENT_ENV_CODE=\"0797\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U7UNW7gv0cm"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eovcELNdvbFo"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip --quiet install python-dotenv neo4j graphdatascience\n",
        "!pip --quiet install langchain_neo4j langchain_openai langgraph\n",
        "# parallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vI-J9kNyxv-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z65Gtwf9v-Ds"
      },
      "source": [
        "## Dotenv configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7AKGiFKZ8Fr",
        "outputId": "b82de6df-8d40-46bc-a955-37fb785f58e4"
      },
      "outputs": [],
      "source": [
        "# Download env file from S3\n",
        "import requests\n",
        "\n",
        "# GCS URL\n",
        "GCS_FILE_URL = \"https://storage.googleapis.com/neo4j-nodes-network/atlanta/student/\"+STUDENT_ENV_CODE+\"/aura.txt\"\n",
        "\n",
        "# Local filename to save\n",
        "LOCAL_ENV_FILE = \"aura.env\"\n",
        "\n",
        "# Fetch the file and write it locally\n",
        "response = requests.get(GCS_FILE_URL)\n",
        "if response.status_code == 200:\n",
        "    with open(LOCAL_ENV_FILE, \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "    print(f\"✅ Environment file downloaded and saved as {LOCAL_ENV_FILE}\")\n",
        "else:\n",
        "    raise Exception(f\"❌ Failed to fetch the .env file: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6xBubKdv9fw",
        "outputId": "14be2599-b4be-4a8a-8467-1b3bfbb24099"
      },
      "outputs": [],
      "source": [
        "# NOTE: Upload files (.env)!!!!\n",
        "# You can skip this cell if not using a ws.env file - alternative to above\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "if os.path.exists(LOCAL_ENV_FILE):\n",
        "     load_dotenv(LOCAL_ENV_FILE, override=True)\n",
        "\n",
        "     # Neo4j\n",
        "     NEO4J_URI = os.getenv('NEO4J_URI')\n",
        "     NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
        "     NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
        "\n",
        "     AURA_API_CLIENT_ID=os.getenv('AURA_API_CLIENT_ID')\n",
        "     AURA_API_CLIENT_SECRET=os.getenv('AURA_API_CLIENT_SECRET')\n",
        "     AURA_API_TENANT_ID=os.getenv('AURA_API_TENANT_ID')\n",
        "     AURA_INSTANCEID=os.getenv('AURA_INSTANCEID')\n",
        "\n",
        "     IS_AURA = os.environ.get(\"AURA\", True) is True\n",
        "\n",
        "     # AI\n",
        "     LLM = 'gpt-4o'\n",
        "     AZURE_OPENAI_API_KEY = os.getenv('AZURE_OPENAI_API_KEY')\n",
        "\n",
        "print(f\"OPENAI_KEY: {AZURE_OPENAI_API_KEY}\")\n",
        "print(f\"AURA_API_TENANT_ID: {AURA_API_TENANT_ID}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izg0UrMdwPEa"
      },
      "source": [
        "## Connecting to Neo4j\n",
        "\n",
        "Provide your Neo4j credentials. We need the DB conection URL, the username (probably neo4j), and your password.\n",
        "\n",
        "If using an env file under the notebook's files folder, reference the:\n",
        "- URI\n",
        "- username\n",
        "- password\n",
        "\n",
        "Log into your Neo4j instance using https://browser.neo4j.io/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsWKgziPwPh2"
      },
      "outputs": [],
      "source": [
        "# # username is neo4j by default\n",
        "# NEO4J_USERNAME = 'neo4j'\n",
        "\n",
        "# # You will need to change these to match your credentials\n",
        "# NEO4J_URI = 'neo4j+s://a51c4bb3.databases.neo4j.io'\n",
        "# NEO4J_PASSWORD = 'R50r64jHpBzFgxZS6tttK7MXwO5agK6syL-Pznw5m_Y'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrkrONA-wZBj"
      },
      "outputs": [],
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "# You can skip this cell if not using a ws.env file - alternative to above\n",
        "# Get credentials from .env file\n",
        "NEO4J_URI = os.getenv('NEO4J_URI')\n",
        "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
        "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
        "\n",
        "# with GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as kg:\n",
        "#     kg.verify_connectivity()\n",
        "\n",
        "kg = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y9Omuu_wj4c"
      },
      "outputs": [],
      "source": [
        "# from graphdatascience import GraphDataScience\n",
        "\n",
        "# gds = GraphDataScience(\n",
        "#     NEO4J_URI,\n",
        "#     auth=(NEO4J_USERNAME, NEO4J_PASSWORD),\n",
        "#     aura_ds=False\n",
        "# )\n",
        "# gds.set_database('neo4j')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GENzhzygyftA"
      },
      "source": [
        "## Test connectivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "qlykXF0dyduQ",
        "outputId": "e0c0719f-80fc-497a-f932-20e64a74f8b5"
      },
      "outputs": [],
      "source": [
        "# total node counts\n",
        "res = kg.execute_query('''\n",
        "    CALL apoc.meta.stats()\n",
        "    YIELD labels\n",
        "    UNWIND keys(labels) AS nodeLabel\n",
        "    RETURN nodeLabel, labels[nodeLabel] AS nodeCount\n",
        "    ORDER BY nodeCount DESC\n",
        "''')\n",
        "\n",
        "# print(res)\n",
        "# for d in res.records:\n",
        "#     print(d.data())\n",
        "\n",
        "df = pd.DataFrame([{'nodeLabel': d['nodeLabel'],\n",
        "               'nodeCount':d['nodeCount']} for d in res.records])\n",
        "df[:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXCLwdzi0n-Z"
      },
      "source": [
        "# Variables and Utility functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loPD4mI6FcAY"
      },
      "source": [
        "## Parallel Execution (MAX_PROCESSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxxi3sDbFY2i"
      },
      "outputs": [],
      "source": [
        "# from parallel import MAX_PROCESSES\n",
        "MAX_PROCESSES = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5h-bWFTMYx9"
      },
      "outputs": [],
      "source": [
        "EXPECTED_SESSIONS_NODE_COUNT = 10000\n",
        "EXPECTED_SESSIONS_RELATIONSHIP_COUNT = 100000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wvcFdrE2b2v"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings, AzureOpenAIEmbeddings\n",
        "\n",
        "DEFAULT_EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
        "COMMENT_VECTOR_INDEX_NAME = \"commentEmbeddings\"\n",
        "ENTITY_VECTOR_INDEX_NAME = \"entityEmbeddings\"\n",
        "OBSERVATION_EMBEDDING_INDEX_NAME = \"observationEmbeddings\"\n",
        "PROCESS_ELEMENT_EMBEDDING_INDEX_NAME = \"processElementEmbeddings\"\n",
        "VECTOR_INDEX_DIM = 128\n",
        "VECTOR_EQUIVALENCE_THRESHOLD = 0.9\n",
        "DEFAULT_k = 7\n",
        "\n",
        "# embedder = OpenAIEmbeddings(model=DEFAULT_EMBEDDING_MODEL, dimensions=VECTOR_INDEX_DIM)\n",
        "\n",
        "embedder = AzureOpenAIEmbeddings(\n",
        "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "    model=DEFAULT_EMBEDDING_MODEL,\n",
        "    openai_api_version=\"2025-01-01-preview\",\n",
        "    dimensions=VECTOR_INDEX_DIM\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Nu4UfuFQCnJ"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "class Entity(BaseModel):\n",
        "    name: str = Field(None, title=\"The name of the entity\")\n",
        "    description: str = Field(None, title=\"A 1-2 sentence description of the entity\")\n",
        "    quote: str = Field(None, title=\"An exactly-copied quote snippet from the chunk that mentions the entity\")\n",
        "\n",
        "class EntityArray(BaseModel):\n",
        "    entities: List[Entity] = Field(None, title=\"An array of extracted entities\")\n",
        "\n",
        "class StateObservation(BaseModel):\n",
        "    state: str = Field(None, title=\"A description of the current state of the conversation\")\n",
        "\n",
        "class ActionSelection(BaseModel):\n",
        "    action: str = Field(None, title=\"A description of the action taken based on the most recent comment\")\n",
        "\n",
        "class DecisionInference(BaseModel):\n",
        "    decision: str = Field(None, title=\"A description of the decision made based on the most recent comment\")\n",
        "\n",
        "class ResolutionInference(BaseModel):\n",
        "    resolution: str = Field(None, title=\"A description of the resolution made based on the call\")\n",
        "\n",
        "class GroupDescription(BaseModel):\n",
        "    name: str = Field(None, title=\"The name of the group\")\n",
        "    description: str = Field(None, title=\"A 1-paragraph description of the group's characteristic ideas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mbp5162IPqz7"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import AzureChatOpenAI, ChatOpenAI\n",
        "# from structured_outputs import EntityArray, StateObservation, ActionSelection, GroupDescription, ResolutionInference\n",
        "\n",
        "# LLM enums\n",
        "FAST_CHAT = \"gpt-4o-mini\"\n",
        "CHAT = \"gpt-4o\"\n",
        "\n",
        "entity_extractor_llm = AzureChatOpenAI(azure_deployment=FAST_CHAT, api_version=\"2025-01-01-preview\", temperature=0).with_structured_output(EntityArray)\n",
        "group_description_llm = AzureChatOpenAI(azure_deployment=FAST_CHAT, api_version=\"2025-01-01-preview\", temperature=0).with_structured_output(GroupDescription)\n",
        "\n",
        "state_observation_llm = AzureChatOpenAI(azure_deployment=FAST_CHAT, api_version=\"2025-01-01-preview\", temperature=0.5).with_structured_output(StateObservation)\n",
        "action_selection_llm = AzureChatOpenAI(azure_deployment=FAST_CHAT, api_version=\"2025-01-01-preview\", temperature=0.5).with_structured_output(ActionSelection)\n",
        "resolution_inference_llm = AzureChatOpenAI(azure_deployment=FAST_CHAT, api_version=\"2025-01-01-preview\", temperature=0.5).with_structured_output(ResolutionInference)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFs0vGTAk56Q"
      },
      "source": [
        "## Create Graph and Vector embeddings stores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY6RIQ1-dTHn"
      },
      "source": [
        "### Create Neo4j DB connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dUPJL0zyjk5"
      },
      "outputs": [],
      "source": [
        "from langchain_neo4j import Neo4jGraph\n",
        "\n",
        "def create_graph_store():\n",
        "    graph_db = Neo4jGraph(url=os.getenv(\"NEO4J_URI\"), username=os.getenv(\"NEO4J_USERNAME\"), password=os.getenv(\"NEO4J_PASSWORD\"))\n",
        "    graph_db.query(\"CREATE CONSTRAINT commentId IF NOT EXISTS FOR (c:Comment) REQUIRE c.id IS NODE KEY\")\n",
        "    graph_db.query(\"CREATE CONSTRAINT callId IF NOT EXISTS FOR (c:Call) REQUIRE c.id IS NODE KEY\")\n",
        "    graph_db.query(\"CREATE CONSTRAINT entityName IF NOT EXISTS FOR (e:Entity) REQUIRE e.name IS NODE KEY\")\n",
        "    graph_db.query(\"CREATE CONSTRAINT customerId IF NOT EXISTS FOR (c:Customer) REQUIRE c.id IS NODE KEY\")\n",
        "    graph_db.query(\"CREATE CONSTRAINT representativeId IF NOT EXISTS FOR (r:Representative) REQUIRE r.id IS NODE KEY\")\n",
        "    graph_db.query(\"CREATE CONSTRAINT observationId IF NOT EXISTS FOR (o:Observation) REQUIRE o.id IS NODE KEY\")\n",
        "    graph_db.query(\"CREATE CONSTRAINT processElementId IF NOT EXISTS FOR (p:ProcessElement) REQUIRE p.id IS NODE KEY\")\n",
        "    return graph_db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK3BmkQfdcA5"
      },
      "source": [
        "### Create Vector Stores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45aN3V2H2ABV"
      },
      "outputs": [],
      "source": [
        "from langchain_neo4j import Neo4jVector\n",
        "\n",
        "# We're using multiple vector indexes because we want to query for chunks and entities separately\n",
        "def create_vector_stores():\n",
        "    comment_vector_db = Neo4jVector(\n",
        "        embedder,\n",
        "        url=os.getenv(\"NEO4J_URI\"),\n",
        "        username=os.getenv(\"NEO4J_USERNAME\"),\n",
        "        password=os.getenv(\"NEO4J_PASSWORD\"),\n",
        "        index_name=COMMENT_VECTOR_INDEX_NAME,\n",
        "        embedding_dimension=VECTOR_INDEX_DIM,\n",
        "        node_label=\"Comment\"\n",
        "    )\n",
        "    comment_vector_db.create_new_index()\n",
        "    entity_vector_db = Neo4jVector(\n",
        "        embedder,\n",
        "        url=os.getenv(\"NEO4J_URI\"),\n",
        "        username=os.getenv(\"NEO4J_USERNAME\"),\n",
        "        password=os.getenv(\"NEO4J_PASSWORD\"),\n",
        "        index_name=ENTITY_VECTOR_INDEX_NAME,\n",
        "        embedding_dimension=VECTOR_INDEX_DIM,\n",
        "        node_label=\"Entity\"\n",
        "    )\n",
        "    entity_vector_db.create_new_index()\n",
        "    observation_vector_db = Neo4jVector(\n",
        "        embedder,\n",
        "        url=os.getenv(\"NEO4J_URI\"),\n",
        "        username=os.getenv(\"NEO4J_USERNAME\"),\n",
        "        password=os.getenv(\"NEO4J_PASSWORD\"),\n",
        "        index_name=OBSERVATION_EMBEDDING_INDEX_NAME,\n",
        "        embedding_dimension=VECTOR_INDEX_DIM,\n",
        "        node_label=\"Observation\"\n",
        "    )\n",
        "    observation_vector_db.create_new_index()\n",
        "    process_element_vector_db = Neo4jVector(\n",
        "        embedder,\n",
        "        url=os.getenv(\"NEO4J_URI\"),\n",
        "        username=os.getenv(\"NEO4J_USERNAME\"),\n",
        "        password=os.getenv(\"NEO4J_PASSWORD\"),\n",
        "        index_name=PROCESS_ELEMENT_EMBEDDING_INDEX_NAME,\n",
        "        embedding_dimension=VECTOR_INDEX_DIM,\n",
        "        node_label=\"ProcessElement\"\n",
        "    )\n",
        "    process_element_vector_db.create_new_index()\n",
        "    return comment_vector_db, entity_vector_db, observation_vector_db, process_element_vector_db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZz-fpz2STqK"
      },
      "source": [
        "## Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2umMD6AvSYpU"
      },
      "outputs": [],
      "source": [
        "POLICIES = [\n",
        "    \"We must have the customer's account number before attempting to resolve their issue.\"\n",
        "]\n",
        "state_observation_prompt = (\n",
        "    \"Please read the conversation and determine the current state of the interaction as of the most recent comment in 1-2 sentences.\\n\"\n",
        "    \"This should include the problem being solved, the current topic of discussion, and the sentiment of the customer.\\n\"\n",
        "    \"Do not mention 'this' conversation, or 'this' customer or representative, but rather describe the situation in abstract terms (i.e., 'the' customer, 'the' account', etc.).\\n\"\n",
        "    \"Please do not mention next steps - this is a snapshot of the current state only.\\n\\n\"\n",
        "    \"When evaluating the state, please consider the following policies and distinguish states based on whether they are satisfied, in addition to general characteristics as described above:\\n\"\n",
        "    + \"\\n\".join(POLICIES) +\n",
        "    \"\\n\\nThe output should be a JSON object with the following format:\\n\\n\"\n",
        "    '{\\n    \"state\": \"Description of the current state of the conversation\"\\n}'\n",
        ")\n",
        "\n",
        "action_selection_prompt = \"\"\"\n",
        "Please read the conversation and determine what action was taken based on the most recent comment.\n",
        "The action is inferred from the most recent comment and the context of the conversation.\n",
        "The action should be described in 1 sentence, 2 max if necessary.\n",
        "Do not say who took the action, but rather say abstractly what the action was.  Respond as if you are figuring out what the employee was told to do before the most recent comment.\n",
        "For instance, instead of saying, \"The employee asked the customer for their account number,\" you would say, \"Ask for the customer's account number.\"\n",
        "Also do not ascribe any reasoning or motivation to the action, just describe the action itself.\n",
        "The output should be a JSON object with the following format:\n",
        "\n",
        "{\n",
        "    \"action\": \"Description of the action taken\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "decision_inference_prompt = \"\"\"\n",
        "Please read the conversation and infer what decision was made based on the most recent comment.\n",
        "The most recent comment represents the decision that was made, so you should infer what the decision was based on the context of the conversation and the transition from the previous comments to the most recent one.\n",
        "Look at the conversation leading up to the most recent comment, then look at the most recent comment itself, and infer what the critical factors were in the thought process.\n",
        "The decision should be described in a few sentences, no more than 1 paragraph.\n",
        "Don't say who made the decision, but describe the likely chain of thought involved in making the decision.\n",
        "When you have determined the decision made, provide a very brief (less than or equal to 1 phrase) name for it.\n",
        "The output should be a JSON object with the following format:\n",
        "\n",
        "{\n",
        "    \"decision\": \"Description of the decision made\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "resolution_inference_prompt = \"\"\"\n",
        "In 1-2 sentences, please describe the resolution of the call with the transcript provided.\n",
        "The resolution should describe the final state of the call, the outcome, the customer sentiment, and the favorability of the outcome to the service provider.\n",
        "The favorability is determined by whether the customer retains their services or increases their spend, as well as how much time or expense the service provider incurred in resolving it.\n",
        "Provide the output in the following format:\n",
        "\n",
        "{\n",
        "    \"resolution\": \"Description of the resolution\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "def group_description_prompt(mode):\n",
        "    # Store example responses as separate variables\n",
        "    example_action = \"\"\"Content:\n",
        "\"Request the customer's account number to check the status.\"\n",
        "\"Request the customer's account number to check the service status.\"\n",
        "\"Request the customer's account number to check their connection status.\"\n",
        "\"Request the customer's account number to check their service.\"\n",
        "\"Request the customer's account number to check their current plan.\"\n",
        "\"Request the customer's account number to check their current plan.\"\n",
        "\"Request the customer's account number to review the bill.\"\n",
        "\"Request the customer's account number to review the charges.\"\n",
        "\"Request the customer's account number to review the bills.\"\n",
        "\n",
        "Answer:\n",
        "{\n",
        "    \"name\": \"Request Account Number\",\n",
        "    \"description\": \"Ask the customer for their account number.\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "    example_general = \"\"\"Content:\n",
        "\"The customer is experiencing internet connectivity issues that occur specifically during rain, which has been linked to potential corrosion caused by bird droppings on the external wiring. The sentiment is positive as the customer is receptive to the employee's suggestion to clean the affected areas.\"\n",
        "\"The customer is experiencing ongoing intermittent internet outages that are impacting their business, expressing frustration over the situation. The employee is actively troubleshooting by checking for external interference and has already attempted several solutions, including restarting the router and updating firmware. The conversation reflects a sense of urgency and concern from the customer.\"\n",
        "\"The customer is experiencing ongoing issues with slow internet speed despite having already restarted their router multiple times. The sentiment is one of frustration as the customer seeks further assistance after initial troubleshooting steps were ineffective.\"\n",
        "\"The customer is experiencing unreliable internet connectivity, which has been an issue for the past week. The employee is currently gathering information to troubleshoot the problem, and the customer has provided details about the location of their modem and router.\"\n",
        "\"The customer is experiencing intermittent internet connectivity issues that correlate with rainy weather. The employee is actively troubleshooting the problem by asking for the customer's account details and conducting basic checks regarding the router's location. The sentiment is cooperative, with both parties engaged in problem-solving.\"\n",
        "\"The customer is experiencing ongoing issues with their internet connection, which has been unreliable for a week despite multiple attempts to reboot the modem and router. The sentiment is one of frustration as the customer seeks a resolution to the recurring problem.\"\n",
        "\"The customer is experiencing an internet connectivity issue that occurs specifically during rain, while other electronic devices function normally. The employee is actively troubleshooting the problem by asking questions about the router's location and other devices.\"\n",
        "\n",
        "Answer:\n",
        "{\n",
        "    \"name\": \"Intermittent and Weather-Related Internet Connectivity Issues\",\n",
        "    \"description\": \"Customers are experiencing internet connectivity issues, often intermittent or weather-related, leading to frustration and a need for troubleshooting. Employees are actively working to diagnose the problems by gathering information, checking external factors, and suggesting solutions, with varying levels of cooperation from customers.\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "    # Select the appropriate example based on mode\n",
        "    example_content = example_action if mode == \"Action\" else example_general\n",
        "\n",
        "    # Build the final string using concatenation (not an f-string)\n",
        "    return (\n",
        "        \"You are an AI designed to distill text passages based on their thematic similarities. \"\n",
        "        \"Your task is to process a set of text strings and generate the following outputs:\\n\\n\"\n",
        "        \"Description \" + (\"(1 sentence)\" if mode == \"Action\" else \"(2 sentences max)\") + \": \" +\n",
        "        (\"The core action that distills the essential meaning of the list of actions.\"\n",
        "         if mode == \"Action\"\n",
        "         else \"Clearly describe the shared themes without referring to the existence of a collection or the act of summarization. Focus on the core issues, sentiments, and actions.\") + \"\\n\"\n",
        "        \"Name (less than 1 sentence): Provide a concise, descriptive label that captures the common theme.\\n\"\n",
        "        \"Avoid phrases like 'the content,' 'the text,' or 'the collection'—instead, directly present the themes and insights.\\n\\n\"\n",
        "        \"For example, given the following content, here is an example of a description and name:\\n\\n\"\n",
        "        + example_content + \"\\n\\n\"\n",
        "        \"Note also that the lines of content are ranked with importance scores, so please weight these appropriately in your analysis.\\n\"\n",
        "        \"The output should be a JSON object with the following format:\\n\\n\"\n",
        "        \"{\\n\"\n",
        "        '    \"name\": \"Generated name\",\\n'\n",
        "        '    \"description\": ' + ('\"The distilled action statement\"' if mode == \"Action\" else '\"Description of the main ideas or themes\"') + '\\n'\n",
        "        \"}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppr14MV39s5k"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_Oha6-iHrwB"
      },
      "outputs": [],
      "source": [
        "from datetime import timedelta\n",
        "from graphdatascience import GraphDataScience\n",
        "from graphdatascience.session import AuraAPICredentials, GdsSessions, DbmsConnectionInfo, AlgorithmCategory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xk-jyWnNCRD"
      },
      "source": [
        "### Read Nodes (Get Calls, Process Observations)\n",
        "At several points in the code we read nodes from the graph. This function abstracts the process of reading nodes and can handle different labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8a-LQDo9Kp5"
      },
      "outputs": [],
      "source": [
        "def read_nodes(graph_db, label=\"Call\", return_label=False):\n",
        "    if label == \"Call\":\n",
        "        nodes = graph_db.query(\"\"\"\n",
        "            MATCH (c:Call)\n",
        "            MATCH (c)-[:FIRST]->(:Comment)-[:NEXT]->*(comm:Comment)<-[:MADE]-(u)\n",
        "            WITH c, collect({\n",
        "                id: comm.id,\n",
        "                content: comm.content,\n",
        "                customer: u:Customer\n",
        "            }) AS comments\n",
        "            RETURN c.id AS id, comments\n",
        "        \"\"\")\n",
        "    else:\n",
        "        nodes = graph_db.query(f\"\"\"\n",
        "            MATCH (n:{label})\n",
        "            RETURN\n",
        "                n.id AS id,\n",
        "                {\"[lbl IN labels(n) WHERE NOT lbl IN ['Observation', 'ProcessElement']][0] AS label,\" if return_label else \"\"}\n",
        "                coalesce(n.description, n.content) AS description\n",
        "        \"\"\")\n",
        "    return nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx3bMlx_NZNm"
      },
      "source": [
        "### Extract Elements of the Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WD_EqWrNPPN"
      },
      "outputs": [],
      "source": [
        "def extract_process_elements(call):\n",
        "    state_observations = []\n",
        "    action_selections = []\n",
        "    # inferred_decisions = []\n",
        "    inferred_resolutions = []\n",
        "    for i, comment in enumerate(call[\"comments\"]):\n",
        "        # The \"subcall\" at position i is the list of comments up to and including the comment at position i\n",
        "        # We don't need this list itself, we'll just put it into a transcript string for the LLM\n",
        "        subcall_transcript = (\n",
        "            \"CALL TRANSCRIPT:\\n\"\n",
        "            + \"\\n\".join(\n",
        "                [f'{\"Customer\" if comm[\"customer\"] else \"Employee\"}: {comm[\"content\"]}'\n",
        "                for comm in call[\"comments\"][:i]]\n",
        "            )\n",
        "            + f\"\\n\\nLATEST COMMENT:\\n{'Customer' if comment['customer'] else 'Employee'}: {comment['content']}\"\n",
        "        )\n",
        "        # for each comment in the call such that comment.customer is True, we need to\n",
        "        #   get all the comments up to and including that comment in a list, and then\n",
        "        #   feed that list into the state observation LLM\n",
        "        if comment[\"customer\"]:\n",
        "            extracted_state = state_observation_llm.invoke([\n",
        "                (\"system\", state_observation_prompt),\n",
        "                (\"human\", subcall_transcript)\n",
        "            ])\n",
        "            state_observations.append({\n",
        "                \"comment_id\": comment[\"id\"],\n",
        "                \"description\": extracted_state.state\n",
        "            })\n",
        "        # for each comment in the call such that comment.customer is False, we need to\n",
        "        #   get all the comments up to and including that comment in a list, and then\n",
        "        #   feed that list into the action selection LLM\n",
        "        else:\n",
        "            extracted_action = action_selection_llm.invoke([\n",
        "                (\"system\", action_selection_prompt),\n",
        "                (\"human\", subcall_transcript)\n",
        "            ])\n",
        "            action_selections.append({\n",
        "                \"comment_id\": comment[\"id\"],\n",
        "                \"description\": extracted_action.action\n",
        "            })\n",
        "            # fetch the resolution node for the call\n",
        "            if i == len(call[\"comments\"]) - 1:\n",
        "                extracted_resolution = resolution_inference_llm.invoke([\n",
        "                    (\"system\", resolution_inference_prompt),\n",
        "                    (\"human\", subcall_transcript)\n",
        "                ])\n",
        "                inferred_resolutions.append({\n",
        "                    \"call_id\": call[\"id\"],\n",
        "                    \"last_comment_id\": comment[\"id\"],\n",
        "                    \"description\": extracted_resolution.resolution\n",
        "                })\n",
        "    return state_observations, action_selections, inferred_resolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEyi6D3kNejH"
      },
      "source": [
        "### Write Process Observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dzvamf9J9yPm"
      },
      "outputs": [],
      "source": [
        "def write_process_observations(calls, graph_db):\n",
        "    for call in calls:\n",
        "        # state_observations, action_selections, inferred_decisions = extract_process_elements(call)\n",
        "        state_observations, action_selections, inferred_resolutions = extract_process_elements(call)\n",
        "        # Create observations\n",
        "        graph_db.query(\"\"\"\n",
        "            UNWIND $states AS state\n",
        "            MATCH (comm:Comment {id: state.comment_id})\n",
        "            CREATE (so:Observation {id: randomUUID()})\n",
        "            MERGE (comm)-[:OBSERVED_STATE]->(so)\n",
        "            SET so:State, so.description = state.description\n",
        "        \"\"\", {\n",
        "            \"states\": state_observations\n",
        "        })\n",
        "        # Create actions\n",
        "        graph_db.query(\"\"\"\n",
        "            UNWIND $actions AS action\n",
        "            MATCH (comm:Comment {id: action.comment_id})\n",
        "            CREATE (ao:Observation {id: randomUUID()})\n",
        "            MERGE (comm)-[:OBSERVED_ACTION]->(ao)\n",
        "            SET ao:Action, ao.description = action.description\n",
        "        \"\"\", {\n",
        "            \"actions\": action_selections\n",
        "        })\n",
        "        # Create resolutions\n",
        "        graph_db.query(\"\"\"\n",
        "            UNWIND $resolutions AS resolution\n",
        "            MATCH (c:Call {id: resolution.call_id})\n",
        "            CREATE (ro:Observation {id: randomUUID()})\n",
        "            MERGE (c)-[:OBSERVED_RESOLUTION]->(ro)\n",
        "            SET ro:Resolution, ro.description = resolution.description\n",
        "        \"\"\", {\n",
        "            \"resolutions\": inferred_resolutions\n",
        "        })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyFsv-n9Nq4P"
      },
      "source": [
        "### Create vector embeddings\n",
        "Embed nodes of a given label\n",
        "\n",
        "Comment nodes embed the `content` property, while other nodes embed the `description` property"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rp0Dq6jY-wqi"
      },
      "outputs": [],
      "source": [
        "def embed_nodes(nodes, graph_db, label=\"Comment\"):\n",
        "    embeddings = embedder.embed_documents([node[\"content\"] if \"content\" in node else node[\"description\"] for node in nodes])\n",
        "    print(\"Storing embeddings...\")\n",
        "    graph_db.query(f\"\"\"\n",
        "        WITH $nodes AS nodes\n",
        "        UNWIND nodes AS node\n",
        "        MATCH (n:{label} {{id: node.id}})\n",
        "        WITH n, node\n",
        "        CALL db.create.setNodeVectorProperty(n, \"embedding\", node.embedding)\n",
        "    \"\"\", {\"nodes\": [{**node, \"embedding\": embedding} for node, embedding in zip(nodes, embeddings)]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRmehY7jNwP2"
      },
      "source": [
        "### Write Transition Relationships\n",
        "Merging the TRANSITION, ACTION_SELECTION, and PROCESS_END relationships between low-level observations\n",
        "\n",
        "We will use these relationships for linking process elements (i.e., communities) later (see `write_lifted_rels`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8ZcgOwzBAK1"
      },
      "outputs": [],
      "source": [
        "def write_transition_rels(graph_db):\n",
        "    graph_db.query(\"\"\"\n",
        "        MATCH (so:Observation)<-[:OBSERVED_STATE]-(c0:Comment)-[:NEXT]->(c1:Comment)-[:OBSERVED_ACTION]->(ao:Observation)\n",
        "        CALL {\n",
        "            WITH so, ao\n",
        "            MERGE (so)-[:OBSERVED_ACTION_SELECTION]->(ao)\n",
        "        } IN TRANSACTIONS OF 1000 ROWS\n",
        "    \"\"\")\n",
        "    graph_db.query(\"\"\"\n",
        "        MATCH (ao:Observation)<-[:OBSERVED_ACTION]-(c0:Comment)-[:NEXT]->(c1:Comment)-[:OBSERVED_STATE]->(so:Observation)\n",
        "        CALL {\n",
        "            WITH so, ao\n",
        "            MERGE (ao)-[:OBSERVED_TRANSITION]->(so)\n",
        "        } IN TRANSACTIONS OF 1000 ROWS\n",
        "    \"\"\")\n",
        "    graph_db.query(\"\"\"\n",
        "        MATCH (ro:Resolution)<-[:OBSERVED_RESOLUTION]-(c:Call)-[:FIRST]->()-[:NEXT]->*(last)\n",
        "        WHERE NOT EXISTS {\n",
        "            (last)-[:NEXT]->()\n",
        "        }\n",
        "        MATCH (last)-->(obs:Observation)\n",
        "        CALL {\n",
        "            WITH ro, obs\n",
        "            MERGE (obs)-[:OBSERVED_PROCESS_END]->(ro)\n",
        "        } IN TRANSACTIONS OF 1000 ROWS\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aEaQZS4S-KS"
      },
      "source": [
        "### Create GDS Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dckBroLSIR5U"
      },
      "outputs": [],
      "source": [
        "def create_graph_data_science_session(session_name):\n",
        "    if IS_AURA:\n",
        "        client_id = os.environ[\"AURA_API_CLIENT_ID\"]\n",
        "        client_secret = os.environ[\"AURA_API_CLIENT_SECRET\"]\n",
        "        # If your account is a member of several tenants, you must also specify the tenant ID to use\n",
        "        tenant_id = os.environ.get(\"AURA_API_TENANT_ID\", None)\n",
        "        sessions = GdsSessions(api_credentials=AuraAPICredentials(client_id, client_secret, tenant_id=tenant_id))\n",
        "        # Estimate the memory needed for the GDS session\n",
        "        memory = sessions.estimate(\n",
        "            node_count=EXPECTED_SESSIONS_NODE_COUNT,\n",
        "            relationship_count=EXPECTED_SESSIONS_RELATIONSHIP_COUNT,\n",
        "            algorithm_categories=[AlgorithmCategory.CENTRALITY, AlgorithmCategory.COMMUNITY_DETECTION],\n",
        "        )\n",
        "        # Identify the AuraDB instance\n",
        "        db_connection = DbmsConnectionInfo(\n",
        "            uri=os.environ[\"NEO4J_URI\"], username=os.environ[\"NEO4J_USERNAME\"], password=os.environ[\"NEO4J_PASSWORD\"]\n",
        "        )\n",
        "        # Create a GDS session!\n",
        "        gds = sessions.get_or_create(\n",
        "            # we give it a representative name\n",
        "            session_name=session_name,\n",
        "            memory=memory,\n",
        "            db_connection=db_connection,\n",
        "            ttl=timedelta(hours=5),\n",
        "        )\n",
        "        return gds\n",
        "    else:\n",
        "        gds = GraphDataScience(\n",
        "            os.getenv(\"NEO4J_URI\"),\n",
        "            auth=(os.getenv(\"NEO4J_USERNAME\"), os.getenv(\"NEO4J_PASSWORD\")),\n",
        "            database=NEO4J_DATABASE,\n",
        "        )\n",
        "        return gds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLUhjHl6OS7Z"
      },
      "source": [
        "### Create GDS Projection\n",
        "Nifty trick here where we project relationships into GDS that don't exist in the graph\n",
        "\n",
        "Injecting a threshold parameter to allow us to easily adjust the similarity threshold during testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjJqsb3NBnqI"
      },
      "outputs": [],
      "source": [
        "def project_process_observations_to_gds(gds, session_name):\n",
        "    threshold = VECTOR_EQUIVALENCE_THRESHOLD\n",
        "    query = f\"\"\"\n",
        "    // CYPHER runtime=parallel  // Use parallel runtime in Aura Business Crtical or Virtual Dedicated Cloud for speed/scale\n",
        "    MATCH (obs:Observation)\n",
        "    OPTIONAL MATCH (similarObs:Observation)\n",
        "    WHERE elementId(obs) <> elementId(similarObs)\n",
        "    // Get all vectors within a certain cosine similarity threshold\n",
        "    AND vector.similarity.cosine(obs.embedding, similarObs.embedding) > {threshold}\n",
        "    AND ((obs:State AND similarObs:State)\n",
        "    OR (obs:Action AND similarObs:Action)\n",
        "    OR (obs:Resolution AND similarObs:Resolution))\n",
        "    // These are not stored relationships, they're on-the-fly computed similarity relations\n",
        "    // Nevertheless, we can project them into a GDS graph via Cypher projection\n",
        "    WITH obs, similarObs, vector.similarity.cosine(obs.embedding, similarObs.embedding) AS score\n",
        "    RETURN gds.graph.project{\".remote\" if IS_AURA else \"\"}({\"\" if IS_AURA else \"$graph_name, \"}obs, similarObs, {{\n",
        "        sourceNodeProperties: {{}},\n",
        "        targetNodeProperties: {{}},\n",
        "        sourceNodeLabels: labels(obs),\n",
        "        targetNodeLabels: labels(similarObs),\n",
        "        relationshipType: \"SIMILAR\",\n",
        "        // Normalize the score to be between 0 and 1\n",
        "        relationshipProperties: {{score: (score - {threshold}) / (1 - {threshold})}}\n",
        "    }})\n",
        "    \"\"\"\n",
        "    if IS_AURA:\n",
        "        G, _ = gds.graph.project(session_name, query, undirected_relationship_types=[\"*\"])\n",
        "    else:\n",
        "        G, _ = gds.graph.cypher.project(query, database=NEO4J_DATABASE, graph_name=session_name)\n",
        "    return G"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRQ08mPhOf76"
      },
      "source": [
        "### Execute Community Detection\n",
        "For communities, we execute GDS algorithms of PageRank and WCC (Weakly Connected Components)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEV0Zl2tDqeH"
      },
      "outputs": [],
      "source": [
        "def process_community_detection(gds, graph):\n",
        "    gds.pageRank.write(graph, writeProperty=\"centrality\")\n",
        "    gds.wcc.write(graph, writeProperty=\"community\")\n",
        "    # Alternate approaches to community detection\n",
        "    # gds.louvain.write(graph, writeProperty=\"community\", relationshipWeightProperty=\"score\")\n",
        "    # gds.leiden.write(graph, writeProperty=\"community\", relationshipWeightProperty=\"score\", gamma=3.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r23b8XubQ7Jt"
      },
      "source": [
        "### Store Process Communities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoFRK0cfU_JL"
      },
      "outputs": [],
      "source": [
        "def write_process_communities(graph_db):\n",
        "    # Materialize the observation communities as process element nodes\n",
        "    graph_db.query(\"\"\"\n",
        "        MATCH (obs:Observation)\n",
        "        WITH obs, obs.community AS community\n",
        "        MERGE (pe:ProcessElement {id: community})\n",
        "        MERGE (obs)-[:IS_PROCESS_ELEMENT]->(pe)\n",
        "        SET obs.community = null\n",
        "    \"\"\")\n",
        "    # Connect the observations to the process elements\n",
        "    graph_db.query(\"\"\"\n",
        "        MATCH (pe:ProcessElement)\n",
        "        WHERE EXISTS {\n",
        "            (pe)<-[:IS_PROCESS_ELEMENT]-(:State)\n",
        "        }\n",
        "        SET pe:State\n",
        "        WITH DISTINCT 1 AS resetCardinality\n",
        "        MATCH (pe:ProcessElement)\n",
        "        WHERE EXISTS {\n",
        "            (pe)<-[:IS_PROCESS_ELEMENT]-(:Action)\n",
        "        }\n",
        "        SET pe:Action\n",
        "        WITH DISTINCT 1 AS resetCardinality\n",
        "        MATCH (pe:ProcessElement)\n",
        "        WHERE EXISTS {\n",
        "            (pe)<-[:IS_PROCESS_ELEMENT]-(:Resolution)\n",
        "        }\n",
        "        SET pe:Resolution\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIpKsX14OzFx"
      },
      "source": [
        "### Close the GDS Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBOd9ni7DynU"
      },
      "outputs": [],
      "source": [
        "def close_gds_session(gds, graph):\n",
        "    # Close the GDS session\n",
        "    # Making sure we don't leave GDS resources projected\n",
        "    if IS_AURA:\n",
        "        # For a GDS session we just delete the session - everything is cleaned up\n",
        "        gds.delete()\n",
        "    else:\n",
        "        # For self-managed, drop the projected graph first\n",
        "        graph.drop()\n",
        "        gds.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3F1pOeUSRN2"
      },
      "source": [
        "### Store 'lifted' relationships\n",
        "Merging relationships between process elements.\n",
        "\n",
        "We take relationships between the observations and \"lift up\" to the process element level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MD7Iow21D7j7"
      },
      "outputs": [],
      "source": [
        "def write_lifted_rels(graph_db):\n",
        "    graph_db.query(\"\"\"\n",
        "        MATCH (pe0:ProcessElement)<-[:IS_PROCESS_ELEMENT]-(o0:Observation)-[r]->(o1:Observation)-[:IS_PROCESS_ELEMENT]->(pe1:ProcessElement)\n",
        "        WITH *,\n",
        "            CASE type(r)\n",
        "                WHEN \"OBSERVED_ACTION_SELECTION\" THEN \"ACTION_SELECTION\"\n",
        "                WHEN \"OBSERVED_TRANSITION\" THEN \"TRANSITION\"\n",
        "                ELSE \"PROCESS_END\"\n",
        "            END AS relType\n",
        "        CALL apoc.merge.relationship(\n",
        "            pe0, relType, {}, {num: 0}, pe1\n",
        "        ) YIELD rel\n",
        "        WITH rel\n",
        "        // Tracking number of connections between any given pair of process elements\n",
        "        SET rel.num = rel.num + 1\n",
        "    \"\"\")\n",
        "    # Edge probabilities in the process map\n",
        "    graph_db.query(\"\"\"\n",
        "        MATCH (pe:ProcessElement)\n",
        "        MATCH (comm:Comment)-->(:Observation)-[:IS_PROCESS_ELEMENT]->(pe)\n",
        "        WITH pe, count(comm) AS numComments\n",
        "        MATCH (pe)-[r]->(:ProcessElement)\n",
        "        SET r.probability = 1.0 * r.num / numComments\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nAkT_xUSufx"
      },
      "source": [
        "### Infer Names for Process Elements\n",
        "Infer names for process elements based on their observations.\n",
        "\n",
        "For each community of process observations, collect a list of descriptions and generate a name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocXUwldVEDiq"
      },
      "outputs": [],
      "source": [
        "def infer_names_for_process_elements(process_element_ids, graph_db):\n",
        "    process_elements = graph_db.query(\"\"\"\n",
        "        UNWIND $processElementIds AS id\n",
        "        MATCH (pe:ProcessElement {id: id})\n",
        "        MATCH (pe)<-[:IS_PROCESS_ELEMENT]-(o:Observation)\n",
        "        WITH pe, collect({\n",
        "            description: o.description,\n",
        "            centrality: o.centrality\n",
        "        }) AS observationDescriptions\n",
        "        RETURN\n",
        "            pe.id AS processElementId,\n",
        "            [label IN labels(pe) WHERE label IN [\"State\", \"Action\", \"Resolution\"]][0] AS label,\n",
        "            apoc.coll.sortMaps(observationDescriptions, \"centrality\") AS observationDescriptions\n",
        "    \"\"\", {\"processElementIds\": process_element_ids})\n",
        "    for process_element in process_elements:\n",
        "        # Generate the process element name and description\n",
        "        group_description_result = group_description_llm.invoke([\n",
        "            (\"system\", group_description_prompt(process_element[\"label\"])),\n",
        "            (\"human\", \"\\n\".join([f\"{obs['description']} ---- Importance Score: {obs['centrality']}\" for obs in process_element['observationDescriptions']])) # Changed this line\n",
        "        ])\n",
        "        name = group_description_result.name\n",
        "        description = group_description_result.description\n",
        "        embedding = embedder.embed_documents([description])[0]\n",
        "        pe_info = {\n",
        "            \"id\": process_element[\"processElementId\"],\n",
        "            \"name\": name,\n",
        "            \"description\": description,\n",
        "            \"embedding\": embedding\n",
        "        }\n",
        "        # Persist the info\n",
        "        graph_db.query(\"\"\"\n",
        "            MATCH (pe:ProcessElement {id: $id})\n",
        "            SET pe.name = $name, pe.description = $description\n",
        "            WITH pe\n",
        "            CALL db.create.setNodeVectorProperty(pe, \"embedding\", $embedding)\n",
        "        \"\"\", pe_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_45RcW-keNI"
      },
      "source": [
        "# Process Discovery Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajtis_-K3xkm"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from typing import List, NotRequired\n",
        "from typing_extensions import TypedDict\n",
        "from graphdatascience import GraphDataScience as GDS\n",
        "from graphdatascience.session.aura_graph_data_science import AuraGraphDataScience as AuraGDS\n",
        "from graphdatascience.graph.graph_object import Graph as GDSGraph\n",
        "# from parallel import MAX_PROCESSES\n",
        "\n",
        "def process_discovery_agent(graph_db, gds, session_name):\n",
        "    class Comment(TypedDict):\n",
        "        id: str\n",
        "        content: str\n",
        "        customer: NotRequired[bool]\n",
        "\n",
        "    class Call(TypedDict):\n",
        "        id: str\n",
        "        messages: List[Comment]\n",
        "\n",
        "    class ProcessElement(TypedDict):\n",
        "        id: str\n",
        "        description: str | None\n",
        "        label: str | None\n",
        "\n",
        "    class Observation(TypedDict):\n",
        "        id: str\n",
        "        description: str\n",
        "\n",
        "    class State(TypedDict):\n",
        "        calls: List[Call]\n",
        "        observations: List[Observation]\n",
        "        process_elements: List[ProcessElement]\n",
        "        gds_graph: GDSGraph | None\n",
        "\n",
        "    def get_calls(state):\n",
        "        print(\"Getting calls from Neo4j...\")\n",
        "        calls = read_nodes(graph_db, label=\"Call\")\n",
        "        print(\"Getting calls from Neo4j complete!\")\n",
        "        return {\"calls\": calls}\n",
        "\n",
        "    def merge_process_observations_batch(i):\n",
        "        def fn(state):\n",
        "            print(f\"Merging process element observations batch {i}...\")\n",
        "            num_calls = len(state[\"calls\"])\n",
        "            calls = state[\"calls\"][i * num_calls // MAX_PROCESSES:(i + 1) * num_calls // MAX_PROCESSES]\n",
        "            write_process_observations(calls, graph_db)\n",
        "            print(f\"Merging process element observations batch {i} complete!\")\n",
        "            return {}\n",
        "        return fn\n",
        "\n",
        "    def get_process_observations(state):\n",
        "        print(\"Getting process element observations from Neo4j...\")\n",
        "        observations = read_nodes(graph_db, label=\"Observation\")\n",
        "        print(\"Getting process element observations from Neo4j complete!\")\n",
        "        return {\"observations\": observations}\n",
        "\n",
        "    def embed_process_observations(state):\n",
        "        print(\"Embedding process element observations...\")\n",
        "        embed_nodes(state[\"observations\"], graph_db, label=\"Observation\")\n",
        "        print(\"Embedding process element observations complete!\")\n",
        "        return {}\n",
        "\n",
        "    def map_transitions(state):\n",
        "        print(\"Mapping TRANSITION relationships...\")\n",
        "        write_transition_rels(graph_db)\n",
        "        print(\"Mapping TRANSITION relationships complete!\")\n",
        "        return {}\n",
        "\n",
        "    def project_gds_graph(state):\n",
        "        print(\"Projecting GDS graph...\")\n",
        "        G = project_process_observations_to_gds(gds, session_name)\n",
        "        print(\"Projecting GDS graph complete!\")\n",
        "        return {\"gds_graph\": G}\n",
        "\n",
        "    def discover_canonical_process_elements(state):\n",
        "        print(\"Discovering canonical process elements...\")\n",
        "        process_community_detection(gds, state[\"gds_graph\"])\n",
        "        write_process_communities(graph_db)\n",
        "        print(\"Discovering canonical process elements complete!\")\n",
        "        return {}\n",
        "\n",
        "    def close_process_gds_session(state):\n",
        "        print(\"Closing GDS session...\")\n",
        "        close_gds_session(gds, state[\"gds_graph\"])\n",
        "        print(\"Closing GDS session complete!\")\n",
        "        return {\"gds_graph\": None}\n",
        "\n",
        "    def lift_up_relationships(state):\n",
        "        print(\"Creating lifted relationships...\")\n",
        "        write_lifted_rels(graph_db)\n",
        "        print(\"Creating lifted relationships complete!\")\n",
        "        return {}\n",
        "\n",
        "    def get_canonical_process_elements(state):\n",
        "        print(\"Getting process elements from Neo4j...\")\n",
        "        process_elements = read_nodes(graph_db, label=\"ProcessElement\", return_label=True)\n",
        "        print(\"Getting process elements from Neo4j complete!\")\n",
        "        return {\"process_elements\": process_elements}\n",
        "\n",
        "    def name_canonical_process_elements_batch(i):\n",
        "        def fn(state):\n",
        "            print(f\"Naming canonical process elements for batch {i}...\")\n",
        "            num_process_elements = len(state[\"process_elements\"])\n",
        "            process_elements = state[\"process_elements\"][i * num_process_elements // MAX_PROCESSES:(i + 1) * num_process_elements // MAX_PROCESSES]\n",
        "            infer_names_for_process_elements([pe[\"id\"] for pe in process_elements], graph_db)\n",
        "            print(f\"Naming canonical process elements for batch {i} complete!\")\n",
        "            return {}\n",
        "        return fn\n",
        "\n",
        "    agent_graph = StateGraph(State)\n",
        "\n",
        "    # defining the agent's workflow\n",
        "    # nodes\n",
        "    agent_graph.add_node(\"get_calls\", get_calls)\n",
        "    agent_graph.add_node(\"get_process_observations\", get_process_observations)\n",
        "    agent_graph.add_node(\"embed_process_observations\", embed_process_observations)\n",
        "    agent_graph.add_node(\"map_transitions\", map_transitions)\n",
        "    agent_graph.add_node(\"project_gds_graph\", project_gds_graph)\n",
        "    agent_graph.add_node(\"discover_canonical_process_elements\", discover_canonical_process_elements)\n",
        "    agent_graph.add_node(\"close_process_gds_session\", close_process_gds_session)\n",
        "    agent_graph.add_node(\"lift_up_relationships\", lift_up_relationships)\n",
        "    agent_graph.add_node(\"get_canonical_process_elements\", get_canonical_process_elements)\n",
        "\n",
        "    # edges\n",
        "    agent_graph.add_edge(START, \"get_calls\")\n",
        "    agent_graph.add_edge(\"get_process_observations\", \"embed_process_observations\")\n",
        "    agent_graph.add_edge(\"get_process_observations\", \"map_transitions\")\n",
        "    agent_graph.add_edge(\"embed_process_observations\", \"project_gds_graph\")\n",
        "    agent_graph.add_edge(\"map_transitions\", \"project_gds_graph\")\n",
        "    agent_graph.add_edge(\"project_gds_graph\", \"discover_canonical_process_elements\")\n",
        "    agent_graph.add_edge(\"discover_canonical_process_elements\", \"close_process_gds_session\")\n",
        "    agent_graph.add_edge(\"close_process_gds_session\", END)\n",
        "    agent_graph.add_edge(\"discover_canonical_process_elements\", \"lift_up_relationships\")\n",
        "    agent_graph.add_edge(\"lift_up_relationships\", \"get_canonical_process_elements\")\n",
        "\n",
        "    # merging process observations\n",
        "    for j in range(MAX_PROCESSES):\n",
        "        agent_graph.add_node(f\"Merge process observations {j}\", merge_process_observations_batch(j))\n",
        "        agent_graph.add_edge(\"get_calls\", f\"Merge process observations {j}\")\n",
        "        agent_graph.add_edge(f\"Merge process observations {j}\", \"get_process_observations\")\n",
        "\n",
        "    # naming canonical process elements\n",
        "    for j in range(MAX_PROCESSES):\n",
        "        agent_graph.add_node(f\"Name canonical process elements {j}\", name_canonical_process_elements_batch(j))\n",
        "        agent_graph.add_edge(\"get_canonical_process_elements\", f\"Name canonical process elements {j}\")\n",
        "        agent_graph.add_edge(f\"Name canonical process elements {j}\", END)\n",
        "\n",
        "    agent = agent_graph.compile()\n",
        "    return agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kppKGKT6l8SY"
      },
      "source": [
        "# Stiching it all together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3e612fa0216b43bc9c57aad9c5bfb3a7",
            "715ab071b54b49a28c081d204e10903b",
            "baf5eae463c24a33bb46fe8c474170c5",
            "bfa8824977f94477b39aa2c3c1331593",
            "f73ad5be0f6b408fbe2137c3a95857a4",
            "0c09b1464b9f4cc8ad7434a7c8603e55",
            "87803ae720374227ba73aa147c1253d5",
            "3852c7770fd84a8fb9df84a3dcc52d88",
            "bae80233ac844b2abfecdca8617567bf",
            "050d04da1da642789fc5648115148cfc",
            "989ea886b1e9493990227a34fb3f6b66",
            "de94fefe6b354779aefb396091911493",
            "e56776db3de3470bbde50f3378789521",
            "f260783e6bcb495da0faa32172299d70",
            "956eefe8adc347f69873640b38960628",
            "ce2f751e501a452c9c3bd53026e42a6f",
            "91a37215cfc24ed49826454f7c058942",
            "d5395cc77641458bbf5dffe55bf3437d",
            "dc3bafe944184660a28697ac277edb0f",
            "4f1c8b6c680b4ea490a13361cd7153d3",
            "847961df0b0a452dacdbdb86c4071fe0",
            "8e4266ef67f2475a8506e647d077258b",
            "3f9320c3f0bb4271936a4489901fac86",
            "ac552ddf6bed48d9bc45c831537b20ce",
            "1dacff1955594303bdfe14612a30fe64",
            "191cec4e92f84c6e97bae05f048f60ef",
            "d7da7e25e2e44d6eb819258cd4b29a4a",
            "5494105c8b6e487f9bf68c5d9577687c",
            "7462bb251be74e188c9e4a34cc77f9f0",
            "2f05804bb3634edb841df2e82b8bc0a1",
            "fa6785e29db747168a0a4af2154f5518",
            "fe548d5d09464eb39a29fb192ec3c1e7",
            "fc18f1c69cd64b2da6d24eb299496f79"
          ]
        },
        "id": "eCQiZrCt11ej",
        "outputId": "36659d40-5fca-4f06-b166-a1b3b7215bb5"
      },
      "outputs": [],
      "source": [
        "# Create the DB connection (and create constraints)\n",
        "graph_db = create_graph_store()\n",
        "\n",
        "comment_vector_db, entity_vector_db, observation_vector_db, process_element_vector_db = create_vector_stores()\n",
        "\n",
        "session_name = \"process_discovery_gds_session-\"+AURA_INSTANCEID\n",
        "gds = create_graph_data_science_session(session_name)\n",
        "\n",
        "res = process_discovery_agent(graph_db, gds, session_name).invoke({\"calls\": []})\n",
        "\n",
        "# Extracting comments and transform into a DataFrame\n",
        "rows = []\n",
        "for call in res['calls']:\n",
        "    call_id = call['id']\n",
        "    for comment in call['comments']:\n",
        "        rows.append({\n",
        "            'call_id': call_id,\n",
        "            'comment_id': comment['id'],\n",
        "            'content': comment['content'],\n",
        "            'customer': comment['customer']\n",
        "        })\n",
        "\n",
        "print('-------------------------------------------------------------------')\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "df[:10]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "050d04da1da642789fc5648115148cfc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c09b1464b9f4cc8ad7434a7c8603e55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "191cec4e92f84c6e97bae05f048f60ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe548d5d09464eb39a29fb192ec3c1e7",
            "placeholder": "​",
            "style": "IPY_MODEL_fc18f1c69cd64b2da6d24eb299496f79",
            "value": " 100.0/100 [00:00&lt;00:00, 519.63%/s, status: FINISHED]"
          }
        },
        "1dacff1955594303bdfe14612a30fe64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f05804bb3634edb841df2e82b8bc0a1",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa6785e29db747168a0a4af2154f5518",
            "value": 100
          }
        },
        "2f05804bb3634edb841df2e82b8bc0a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3852c7770fd84a8fb9df84a3dcc52d88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e612fa0216b43bc9c57aad9c5bfb3a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_715ab071b54b49a28c081d204e10903b",
              "IPY_MODEL_baf5eae463c24a33bb46fe8c474170c5",
              "IPY_MODEL_bfa8824977f94477b39aa2c3c1331593"
            ],
            "layout": "IPY_MODEL_f73ad5be0f6b408fbe2137c3a95857a4"
          }
        },
        "3f9320c3f0bb4271936a4489901fac86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac552ddf6bed48d9bc45c831537b20ce",
              "IPY_MODEL_1dacff1955594303bdfe14612a30fe64",
              "IPY_MODEL_191cec4e92f84c6e97bae05f048f60ef"
            ],
            "layout": "IPY_MODEL_d7da7e25e2e44d6eb819258cd4b29a4a"
          }
        },
        "4f1c8b6c680b4ea490a13361cd7153d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5494105c8b6e487f9bf68c5d9577687c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "715ab071b54b49a28c081d204e10903b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c09b1464b9f4cc8ad7434a7c8603e55",
            "placeholder": "​",
            "style": "IPY_MODEL_87803ae720374227ba73aa147c1253d5",
            "value": " Graph creation from Triplets: 100%"
          }
        },
        "7462bb251be74e188c9e4a34cc77f9f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "847961df0b0a452dacdbdb86c4071fe0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87803ae720374227ba73aa147c1253d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e4266ef67f2475a8506e647d077258b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91a37215cfc24ed49826454f7c058942": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "956eefe8adc347f69873640b38960628": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_847961df0b0a452dacdbdb86c4071fe0",
            "placeholder": "​",
            "style": "IPY_MODEL_8e4266ef67f2475a8506e647d077258b",
            "value": " 100.0/100 [00:00&lt;00:00, 354.27%/s, status: FINISHED]"
          }
        },
        "989ea886b1e9493990227a34fb3f6b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac552ddf6bed48d9bc45c831537b20ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5494105c8b6e487f9bf68c5d9577687c",
            "placeholder": "​",
            "style": "IPY_MODEL_7462bb251be74e188c9e4a34cc77f9f0",
            "value": " Node properties export: 100%"
          }
        },
        "bae80233ac844b2abfecdca8617567bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "baf5eae463c24a33bb46fe8c474170c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3852c7770fd84a8fb9df84a3dcc52d88",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bae80233ac844b2abfecdca8617567bf",
            "value": 100
          }
        },
        "bfa8824977f94477b39aa2c3c1331593": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_050d04da1da642789fc5648115148cfc",
            "placeholder": "​",
            "style": "IPY_MODEL_989ea886b1e9493990227a34fb3f6b66",
            "value": " 100.0/100 [00:11&lt;00:00, 141.54%/s, status: FINISHED]"
          }
        },
        "ce2f751e501a452c9c3bd53026e42a6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5395cc77641458bbf5dffe55bf3437d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7da7e25e2e44d6eb819258cd4b29a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc3bafe944184660a28697ac277edb0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de94fefe6b354779aefb396091911493": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e56776db3de3470bbde50f3378789521",
              "IPY_MODEL_f260783e6bcb495da0faa32172299d70",
              "IPY_MODEL_956eefe8adc347f69873640b38960628"
            ],
            "layout": "IPY_MODEL_ce2f751e501a452c9c3bd53026e42a6f"
          }
        },
        "e56776db3de3470bbde50f3378789521": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91a37215cfc24ed49826454f7c058942",
            "placeholder": "​",
            "style": "IPY_MODEL_d5395cc77641458bbf5dffe55bf3437d",
            "value": " PageRank: 100%"
          }
        },
        "f260783e6bcb495da0faa32172299d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc3bafe944184660a28697ac277edb0f",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f1c8b6c680b4ea490a13361cd7153d3",
            "value": 100
          }
        },
        "f73ad5be0f6b408fbe2137c3a95857a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa6785e29db747168a0a4af2154f5518": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc18f1c69cd64b2da6d24eb299496f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe548d5d09464eb39a29fb192ec3c1e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
